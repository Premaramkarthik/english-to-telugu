{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecf9559-5974-460b-aa3a-d1aa7e3820f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf989c57-197e-495e-8d56-139397adb8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\saich\\Downloads\\English-Telugu (2).csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1042869-6bf9-4aee-a27d-7d4aa3a3e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English --> Encoder ---> longtermsequences, shortterm sequences --> concat \n",
    "# concat --> Decoder ---> target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50d42905-51af-4300-b0c8-9315236a304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Telugu\"] = \"start\" + \" \" + df[\"Telugu\"] + \" \" + \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76d92801-5f8c-4aa7-8386-e3724ded3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text to words\n",
    "# fit the tokenizer on words\n",
    "\n",
    "\n",
    "df[\"English\" ] = df[\"English\"].apply(lambda iterable: word_tokenize(iterable))\n",
    "df[\"Telugu\" ] = df[\"Telugu\"].apply(lambda iterable: word_tokenize(iterable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfeff41d-c8b7-4543-b4db-89114cf50eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tokenizer = Tokenizer()\n",
    "telugu_tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cda916a-1d7c-4b06-b6ee-dd03d66fb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10c34271-47fd-45de-bbb2-3e5706e727c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tokenizer.fit_on_texts(df[\"English\"])\n",
    "telugu_tokenizer.fit_on_texts(df[\"Telugu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42742412-cbc3-45b7-ac8d-5fd700da4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513\n",
      "2285\n"
     ]
    }
   ],
   "source": [
    "print(len(english_tokenizer.word_index))\n",
    "print(len(telugu_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d13a0e3f-5278-4854-a435-434e4c01db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sequences = english_tokenizer.texts_to_sequences(df[\"English\"])\n",
    "telugu_sequences = telugu_tokenizer.texts_to_sequences(df[\"Telugu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04c76b38-2528-4cae-bd7e-08f2ca8eab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # padding based on maximum lenght of two sequences\n",
    "\n",
    "# english_sequences = pad_sequences(english_sequences,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f392b0-207f-4e7d-aaf9-5f4b5ea84955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105, 31)\n",
      "(1105, 29)\n"
     ]
    }
   ],
   "source": [
    "# print(english_sequences.shape)\n",
    "# print(telugu_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "669ddbb3-37cf-46f8-ade4-0f2bad4a4762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 37, 574, 575, 51, 3, 2]\n",
      "[1, 37, 574, 575, 51, 3]\n",
      "[37, 574, 575, 51, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(telugu_sequences[0])\n",
    "print(telugu_sequences[0][:-1]) # decoder input\n",
    "print(telugu_sequences[0][1:]) # decoder output\n",
    "# 1 represents start\n",
    "# 2 reprensents end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57148b72-1008-4f4f-a4c2-0f4ea3996f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = [seq for seq in telugu_sequences[:-1]]\n",
    "decoder_inputs = pad_sequences(decoder_inputs,padding=\"post\")\n",
    "decoder_outputs = [seq for seq in telugu_sequences[1:]]\n",
    "decoder_outputs = pad_sequences(decoder_outputs,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff026733-11e7-4984-bad0-df32635ae2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1104, 29)\n",
      "(1104, 29, 2286)\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = keras.utils.to_categorical(decoder_outputs,num_classes=2286)\n",
    "\n",
    "print(decoder_inputs.shape)\n",
    "print(decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f412c2a-6b0f-4f25-b69a-678f25c885ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will have to create input for decoder and output for decoder\n",
    "\n",
    "# input_decoder --> remove end from the sequences\n",
    "# output_decoder --> remove start from the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb257dd1-de95-4098-a8db-1344581d1703",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '1514' to a shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Encoder Part\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m encoder_inputs = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1514\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m encoder = keras.layers.LSTM(\u001b[32m256\u001b[39m, return_state=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\project_cnn\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:209\u001b[39m, in \u001b[36mInput\u001b[39m\u001b[34m(shape, batch_size, dtype, sparse, ragged, batch_shape, name, tensor, optional)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mkeras.layers.Input\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.Input\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mInput\u001b[39m(\n\u001b[32m    146\u001b[39m     shape=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m     optional=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    155\u001b[39m ):\n\u001b[32m    156\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Used to instantiate a Keras tensor.\u001b[39;00m\n\u001b[32m    157\u001b[39m \n\u001b[32m    158\u001b[39m \u001b[33;03m    A Keras tensor is a symbolic tensor-like object, which we augment with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     layer = \u001b[43mInputLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mragged\u001b[49m\u001b[43m=\u001b[49m\u001b[43mragged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer.output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\project_cnn\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:92\u001b[39m, in \u001b[36mInputLayer.__init__\u001b[39m\u001b[34m(self, shape, batch_size, dtype, sparse, ragged, batch_shape, input_tensor, optional, name, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must pass a `shape` argument.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m         shape = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m         batch_shape = (batch_size,) + shape\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m._batch_shape = backend.standardize_shape(batch_shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\project_cnn\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:587\u001b[39m, in \u001b[36mstandardize_shape\u001b[39m\u001b[34m(shape)\u001b[39m\n\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUndefined shapes are not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(shape, \u001b[33m\"\u001b[39m\u001b[33m__iter__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.backend() == \u001b[33m\"\u001b[39m\u001b[33mtensorflow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, tf.TensorShape):\n\u001b[32m    590\u001b[39m         \u001b[38;5;66;03m# `tf.TensorShape` may contain `Dimension` objects.\u001b[39;00m\n\u001b[32m    591\u001b[39m         \u001b[38;5;66;03m# We need to convert the items in it to either int or `None`\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Cannot convert '1514' to a shape."
     ]
    }
   ],
   "source": [
    "# Encoder Part\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None, 1514))\n",
    "encoder = keras.layers.LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder Part\n",
    "decoder_inputs = keras.Input(shape=(None, 2286))\n",
    "decoder_lstm = keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(2286, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(2286)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b0a13-46e1-4fff-a32b-8fe88b7d9e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
